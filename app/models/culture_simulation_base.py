"""
ğŸŒˆ æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ« ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºç›¤
Higher Kindæ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡åŒ–é€²åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

Author: ã‚·ã‚¹ãƒ†ãƒ³ã‚¹ã‚«ãƒ•ã‚§ ãƒ†ãƒƒã‚¯ãƒãƒ¼ãƒ 
Date: 2025-06-21
"""

from typing import Dict, List, Any, Optional, AsyncIterable, Protocol
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import asyncio
import json
from abc import ABC, abstractmethod

# Avoid circular imports - import LLM components dynamically when needed


# ===== åŸºæœ¬çš„ãªæ–‡åŒ–è¦ç´  =====

class ValueCategory(Enum):
    COGNITIVE = "cognitive"     # èªçŸ¥çš„ä¾¡å€¤è¦³ (è«–ç†vsç›´æ„Ÿ)
    SOCIAL = "social"          # ç¤¾ä¼šçš„ä¾¡å€¤è¦³ (å€‹äººvsé›†å›£)
    TEMPORAL = "temporal"      # æ™‚é–“çš„ä¾¡å€¤è¦³ (çŸ­æœŸvsé•·æœŸ)
    AESTHETIC = "aesthetic"    # ç¾çš„ä¾¡å€¤è¦³ (èª¿å’Œvsé©æ–°)
    EMOTIONAL = "emotional"    # æ„Ÿæƒ…çš„ä¾¡å€¤è¦³ (è¡¨ç¾vsæŠ‘åˆ¶)


@dataclass
class ValueToken:
    """ä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ - ä¾¡å€¤è¦³ã‚’è»¸ã«æ•°å€¤åŒ–ã—ãŸã‚‚ã®"""
    name: str
    value: float  # 0.0-1.0ã§ã®é‡ã¿
    influence: float  # ä»–ã®è¦ç´ ã¸ã®å½±éŸ¿åº¦
    category: ValueCategory


@dataclass
class Meme:
    """ãƒŸãƒ¼ãƒ  - æ–‡åŒ–ç‹¬è‡ªã®ä¾¡å€¤ã‚’æŒã¤ç™ºè¨€ã‚„è€ƒãˆã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŠ¹æœã§æ³¢åŠã™ã‚‹"""
    content: str
    virality: float  # 0.0-1.0ã§ã®æ‹¡æ•£åŠ›
    resonance: float  # æ–‡åŒ–å†…ã§ã®å…±é³´åº¦
    origin: str
    mutations: List['Meme'] = field(default_factory=list)


class PracticeContext(Enum):
    DECISION_MAKING = "decision_making"
    COMMUNICATION = "communication"
    PROBLEM_SOLVING = "problem_solving"
    RELATIONSHIP = "relationship"
    LEARNING = "learning"


@dataclass
class Practice:
    """æ§˜å¼ - æ–‡åŒ–ç‹¬è‡ªã®è¡Œå‹•è¦ç¯„ã€å„€å¼çš„è¡Œç‚ºãƒ»ã‚¸ãƒ£ãƒ¼ã‚´ãƒ³ãªã©ã‚’å«ã‚€ä»»æ„ã®å½¢å¼"""
    name: str
    description: str
    frequency: float  # 0.0-1.0ã§ã®å®Ÿè¡Œé »åº¦
    context: PracticeContext
    triggers: List[str]
    outcomes: List[str]


@dataclass
class Myth:
    """ç¥è©± - æ–‡åŒ–ã®è¦ç¯„ã‚„å‡ºè‡ªã‚’è±¡å¾´çš„ã«è¡¨ã—ãŸã‚‚ã®"""
    name: str
    narrative: str
    symbolism: str
    archetypes: List[str]
    influence: float  # æ–‡åŒ–ã¸ã®å½±éŸ¿åº¦


class CultureOrigin(Enum):
    HISTORICAL = "historical"     # å®Ÿåœ¨ã®æ–‡åŒ–ã‹ã‚‰æŠ½å‡º
    SYNTHETIC = "synthetic"       # äººå·¥çš„ã«åˆæˆ
    EVOLVED = "evolved"          # æ—¢å­˜ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰é€²åŒ–
    EXPERIMENTAL = "experimental" # å®Ÿé¨“çš„ã«å‰µé€ 


# ===== æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«æœ¬ä½“ =====

@dataclass
class CultureProtocol:
    """æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ« - 4ã¤ã®è¦ç´ ã®çµ„ã¿åˆã‚ã›ã§è¡¨ç¾ã•ã‚Œã‚‹èªçŸ¥æ§˜å¼"""
    id: str
    name: str
    description: str
    
    # æ–‡åŒ–å­¦çš„æ§‹æˆè¦ç´ 
    value_tokens: List[ValueToken]
    memes: List[Meme]
    practices: List[Practice]
    myths: List[Myth]
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    origin: CultureOrigin
    version: str
    created_at: datetime
    tags: List[str]
    
    def to_system_prompt(self) -> str:
        """æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›"""
        prompt_parts = [
            f"ã‚ãªãŸã¯ã€Œ{self.name}ã€æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½“ç¾ã™ã‚‹å­˜åœ¨ã§ã™ã€‚",
            f"æ–‡åŒ–çš„ç‰¹å¾´: {self.description}",
            "",
            "ã€ä¾¡å€¤è¦³ã€‘"
        ]
        
        for token in self.value_tokens:
            prompt_parts.append(f"- {token.name} (é‡è¦åº¦: {token.value:.1f})")
        
        prompt_parts.append("\nã€è¡Œå‹•æ§˜å¼ã€‘")
        for practice in self.practices:
            prompt_parts.append(f"- {practice.name}: {practice.description}")
        
        prompt_parts.append("\nã€æ–‡åŒ–çš„ãƒŸãƒ¼ãƒ ã€‘")
        for meme in self.memes:
            prompt_parts.append(f"- ã€Œ{meme.content}ã€")
        
        prompt_parts.append("\nã€ç¥è©±ãƒ»è±¡å¾´ã€‘")
        for myth in self.myths:
            prompt_parts.append(f"- {myth.name}: {myth.symbolism}")
        
        prompt_parts.append("\nã“ã®æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¾“ã£ã¦æ€è€ƒã—ã€å¿œç­”ã—ã¦ãã ã•ã„ã€‚")
        
        return "\n".join(prompt_parts)


# ===== æ–‡åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  =====

@dataclass
class AgentPersonality:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å€‹æ€§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    curiosity: float      # å¥½å¥‡å¿ƒ (0.0-1.0)
    conservatism: float   # ä¿å®ˆæ€§ (0.0-1.0)
    sociability: float    # ç¤¾äº¤æ€§ (0.0-1.0)
    creativity: float     # å‰µé€ æ€§ (0.0-1.0)
    adaptability: float   # é©å¿œæ€§ (0.0-1.0)


@dataclass
class LLMConfig:
    """LLMè¨­å®š"""
    model: str = "llama-3.1-70b"
    temperature: float = 0.7
    max_tokens: int = 500
    memory_size: int = 20


class CultureAgent:
    """æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(
        self, 
        agent_id: str,
        culture: CultureProtocol,
        personality: AgentPersonality,
        llm_config: LLMConfig
    ):
        self.agent_id = agent_id
        self.culture = culture
        self.personality = personality
        self.llm_config = llm_config
        self.memory: List[Dict[str, Any]] = []
        self.interaction_history: List[Dict[str, Any]] = []
    
    async def respond_to_situation(self, situation: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """çŠ¶æ³ã«å¯¾ã™ã‚‹æ–‡åŒ–çš„å¿œç­”ã‚’ç”Ÿæˆ"""
        
        # æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        system_prompt = self.culture.to_system_prompt()
        
        # å€‹æ€§ã®åæ˜ 
        personality_prompt = self._generate_personality_prompt()
        
        # çŠ¶æ³ã¸ã®å¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
        response_prompt = f"""
ã‚ãªãŸã¯ã€Œ{self.culture.name}ã€ã®æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

æ–‡åŒ–çš„ç‰¹å¾´:
- {self.culture.description}
- ä¸»ãªä¾¡å€¤è¦³: {', '.join([token.name for token in self.culture.value_tokens[:3]])}
- è¡Œå‹•æ§˜å¼: {self.culture.practices[0].name if self.culture.practices else 'æ…é‡ãªåˆ†æ'}

å€‹æ€§: {personality_prompt}

çŠ¶æ³: {situation}

ã“ã®çŠ¶æ³ã«å¯¾ã—ã¦ã€ã‚ãªãŸã®æ–‡åŒ–çš„ä¾¡å€¤è¦³ã¨å€‹æ€§ã«åŸºã¥ã„ã¦å¿œç­”ã—ã¦ãã ã•ã„ã€‚
ç°¡æ½”ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        try:
            # Dynamic import to avoid circular dependency
            from app.services.llm_client import llm_client
            
            response = await llm_client.generate(
                response_prompt,
                max_tokens=self.llm_config.max_tokens
            )
            
            # å¿œç­”ã‚’ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
            interaction = {
                "timestamp": datetime.now(),
                "situation": situation,
                "context": context,
                "response": response,
                "culture_influence": self._analyze_culture_influence(response)
            }
            
            self.interaction_history.append(interaction)
            
            # ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºåˆ¶é™
            if len(self.interaction_history) > self.llm_config.memory_size:
                self.interaction_history = self.interaction_history[-self.llm_config.memory_size:]
            
            return {
                "agent_id": self.agent_id,
                "culture_name": self.culture.name,
                "response": response.strip(),
                "cultural_analysis": interaction["culture_influence"],
                "personality_bias": self._get_personality_bias(),
                "timestamp": interaction["timestamp"]
            }
            
        except Exception as e:
            return {
                "agent_id": self.agent_id,
                "culture_name": self.culture.name,
                "response": f"[{self.culture.name}ã®ç«‹å ´ã‹ã‚‰] çŠ¶æ³ã‚’ç†è§£ã—ã€æ…é‡ã«å¯¾å¿œã—ãŸã„ã¨æ€ã„ã¾ã™ã€‚",
                "cultural_analysis": {
                    "dominant_values": [],
                    "applied_practices": [],
                    "meme_usage": [],
                    "cultural_coherence": 0.0
                },
                "personality_bias": self._get_personality_bias(),
                "error": str(e),
                "timestamp": datetime.now()
            }
    
    def _generate_personality_prompt(self) -> str:
        """å€‹æ€§ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¤‰æ›"""
        traits = []
        
        if self.personality.curiosity > 0.7:
            traits.append("éå¸¸ã«å¥½å¥‡å¿ƒæ—ºç››ã§æ–°ã—ã„ã“ã¨ã«èˆˆå‘³ã‚’ç¤ºã™")
        elif self.personality.curiosity < 0.3:
            traits.append("æ…é‡ã§æ—¢çŸ¥ã®ã“ã¨ã‚’å¥½ã‚€")
        
        if self.personality.sociability > 0.7:
            traits.append("ç¤¾äº¤çš„ã§ä»–è€…ã¨ã®å”åƒã‚’é‡è¦–ã™ã‚‹")
        elif self.personality.sociability < 0.3:
            traits.append("å†…å‘çš„ã§ç‹¬ç«‹ã—ãŸæ€è€ƒã‚’å¥½ã‚€")
        
        if self.personality.creativity > 0.7:
            traits.append("å‰µé€ çš„ã§æ–°ã—ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿã¿å‡ºã™")
        elif self.personality.creativity < 0.3:
            traits.append("å®Ÿç”¨çš„ã§ç¢ºå®Ÿãªæ–¹æ³•ã‚’é¸ã¶")
        
        return "ã€".join(traits) if traits else "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§æ ¼"
    
    def _analyze_culture_influence(self, response: str) -> Dict[str, Any]:
        """å¿œç­”ã¸ã®æ–‡åŒ–çš„å½±éŸ¿ã‚’åˆ†æ"""
        analysis = {
            "dominant_values": [],
            "applied_practices": [],
            "meme_usage": [],
            "cultural_coherence": 0.0
        }
        
        # ç°¡æ˜“çš„ãªåˆ†æï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰
        response_lower = response.lower()
        
        # ä¾¡å€¤è¦³ã®å½±éŸ¿
        for token in self.culture.value_tokens:
            if any(keyword in response_lower for keyword in token.name.lower().split()):
                analysis["dominant_values"].append(token.name)
        
        # ãƒŸãƒ¼ãƒ ã®ä½¿ç”¨
        for meme in self.culture.memes:
            if any(word in response_lower for word in meme.content.lower().split()[:3]):
                analysis["meme_usage"].append(meme.content)
        
        # æ–‡åŒ–çš„ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        cultural_elements_found = len(analysis["dominant_values"]) + len(analysis["meme_usage"])
        total_cultural_elements = len(self.culture.value_tokens) + len(self.culture.memes)
        
        if total_cultural_elements > 0:
            analysis["cultural_coherence"] = min(cultural_elements_found / total_cultural_elements, 1.0)
        
        return analysis
    
    def _get_personality_bias(self) -> Dict[str, float]:
        """å€‹æ€§ã®åå‘ã‚’è¿”ã™"""
        return {
            "curiosity_bias": self.personality.curiosity,
            "social_bias": self.personality.sociability,
            "creative_bias": self.personality.creativity,
            "conservative_bias": self.personality.conservatism,
            "adaptive_bias": self.personality.adaptability
        }


# ===== ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ =====

class ChallengeType(Enum):
    PROBLEM_SOLVING = "problem_solving"
    RESOURCE_ALLOCATION = "resource_allocation"
    CONFLICT_RESOLUTION = "conflict_resolution"
    CREATIVE_TASK = "creative_task"
    COLLABORATION = "collaboration"
    ADAPTATION = "adaptation"


@dataclass
class Challenge:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³èª²é¡Œ"""
    type: ChallengeType
    difficulty: float  # é›£æ˜“åº¦ (0.0-1.0)
    description: str
    required_capabilities: List[str]


@dataclass
class Scenario:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒŠãƒªã‚ª"""
    id: str
    name: str
    description: str
    challenges: List[Challenge]
    time_limit: int  # ã‚¿ãƒ¼ãƒ³æ•°
    success_criteria: List[str]


@dataclass
class SimulationEnvironment:
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒ"""
    scenario: Scenario
    agents: List[CultureAgent]
    current_turn: int = 0
    events: List[Dict[str, Any]] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)


# ===== æ–‡åŒ–é€²åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ =====

class CultureEvolutionSimulator:
    """æ–‡åŒ–é€²åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.environments: Dict[str, SimulationEnvironment] = {}
        self.evolution_history: List[Dict[str, Any]] = []
    
    def create_environment(
        self, 
        env_id: str,
        scenario: Scenario,
        agents: List[CultureAgent]
    ) -> SimulationEnvironment:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‚’ä½œæˆ"""
        environment = SimulationEnvironment(
            scenario=scenario,
            agents=agents
        )
        
        self.environments[env_id] = environment
        return environment
    
    async def run_simulation_step(
        self, 
        env_id: str,
        situation: str,
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®1ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ"""
        
        if env_id not in self.environments:
            raise ValueError(f"Environment {env_id} not found")
        
        environment = self.environments[env_id]
        
        # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å¿œç­”ã‚’åé›†
        responses = []
        for agent in environment.agents:
            response = await agent.respond_to_situation(situation, context)
            responses.append(response)
        
        # ã‚¹ãƒ†ãƒƒãƒ—çµæœã‚’è¨˜éŒ²
        step_result = {
            "environment_id": env_id,
            "turn": environment.current_turn,
            "situation": situation,
            "context": context,
            "agent_responses": responses,
            "timestamp": datetime.now(),
            "cultural_diversity": self._calculate_cultural_diversity(responses),
            "interaction_quality": self._evaluate_interaction_quality(responses)
        }
        
        # ç’°å¢ƒã‚’æ›´æ–°
        environment.current_turn += 1
        environment.events.append(step_result)
        
        return step_result
    
    async def run_multi_turn_simulation(
        self,
        env_id: str,
        scenarios: List[Dict[str, Any]],
        max_turns: int = 10
    ) -> Dict[str, Any]:
        """è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        
        results = []
        
        for turn in range(min(len(scenarios), max_turns)):
            scenario_data = scenarios[turn]
            situation = scenario_data.get("situation", f"ã‚¿ãƒ¼ãƒ³ {turn + 1} ã®çŠ¶æ³")
            context = scenario_data.get("context", {})
            
            step_result = await self.run_simulation_step(env_id, situation, context)
            results.append(step_result)
            
            # çŸ­ã„ä¼‘æ¯ã‚’å…¥ã‚Œã‚‹
            await asyncio.sleep(0.1)
        
        # æœ€çµ‚çµæœã®åˆ†æ
        final_analysis = {
            "environment_id": env_id,
            "total_turns": len(results),
            "step_results": results,
            "evolution_summary": self._analyze_cultural_evolution(results),
            "emergent_patterns": self._detect_emergent_patterns(results),
            "final_cultural_state": self._get_cultural_state_snapshot(env_id)
        }
        
        self.evolution_history.append(final_analysis)
        
        return final_analysis
    
    def _calculate_cultural_diversity(self, responses: List[Dict[str, Any]]) -> float:
        """æ–‡åŒ–çš„å¤šæ§˜æ€§ã‚’è¨ˆç®—"""
        if len(responses) < 2:
            return 0.0
        
        # æ–‡åŒ–åã®å¤šæ§˜æ€§
        cultures = set(r.get("culture_name", "") for r in responses)
        diversity_score = len(cultures) / len(responses)
        
        return diversity_score
    
    def _evaluate_interaction_quality(self, responses: List[Dict[str, Any]]) -> float:
        """ç›¸äº’ä½œç”¨ã®è³ªã‚’è©•ä¾¡"""
        # ç°¡æ˜“çš„ãªè©•ä¾¡ï¼ˆå¿œç­”ã®é•·ã•ã¨æ–‡åŒ–çš„ä¸€è²«æ€§ï¼‰
        total_quality = 0.0
        
        for response in responses:
            response_length = len(response.get("response", ""))
            cultural_coherence = response.get("cultural_analysis", {}).get("cultural_coherence", 0.0)
            
            quality = (min(response_length / 100, 1.0) * 0.5) + (cultural_coherence * 0.5)
            total_quality += quality
        
        return total_quality / len(responses) if responses else 0.0
    
    def _analyze_cultural_evolution(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ–‡åŒ–é€²åŒ–ã®åˆ†æ"""
        return {
            "diversity_trend": [r["cultural_diversity"] for r in results],
            "quality_trend": [r["interaction_quality"] for r in results],
            "dominant_cultures": self._identify_dominant_cultures(results),
            "cultural_shifts": self._detect_cultural_shifts(results)
        }
    
    def _detect_emergent_patterns(self, results: List[Dict[str, Any]]) -> List[str]:
        """å‰µç™ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º"""
        patterns = []
        
        # æ–‡åŒ–çš„å¤šæ§˜æ€§ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³
        diversities = [r["cultural_diversity"] for r in results]
        if len(diversities) > 1:
            if diversities[-1] > diversities[0]:
                patterns.append("æ–‡åŒ–çš„å¤šæ§˜æ€§ã®å¢—åŠ ")
            elif diversities[-1] < diversities[0]:
                patterns.append("æ–‡åŒ–çš„åæŸ")
        
        # ç›¸äº’ä½œç”¨ã®è³ªã®å¤‰åŒ–
        qualities = [r["interaction_quality"] for r in results]
        if len(qualities) > 1:
            if qualities[-1] > qualities[0]:
                patterns.append("ç›¸äº’ä½œç”¨ã®è³ªã®å‘ä¸Š")
        
        return patterns
    
    def _identify_dominant_cultures(self, results: List[Dict[str, Any]]) -> List[str]:
        """æ”¯é…çš„æ–‡åŒ–ã®ç‰¹å®š"""
        culture_frequency = {}
        
        for result in results:
            for response in result["agent_responses"]:
                culture = response.get("culture_name", "Unknown")
                culture_frequency[culture] = culture_frequency.get(culture, 0) + 1
        
        # é »åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_cultures = sorted(culture_frequency.items(), key=lambda x: x[1], reverse=True)
        return [culture for culture, _ in sorted_cultures[:3]]
    
    def _detect_cultural_shifts(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ–‡åŒ–çš„å¤‰åŒ–ã®æ¤œå‡º"""
        shifts = []
        
        if len(results) > 1:
            # ç°¡æ˜“çš„ãªå¤‰åŒ–æ¤œå‡º
            for i in range(1, len(results)):
                prev_diversity = results[i-1]["cultural_diversity"]
                curr_diversity = results[i]["cultural_diversity"]
                
                if abs(curr_diversity - prev_diversity) > 0.2:
                    shifts.append({
                        "turn": i,
                        "type": "diversity_shift",
                        "magnitude": curr_diversity - prev_diversity,
                        "description": f"ã‚¿ãƒ¼ãƒ³{i}ã§æ–‡åŒ–çš„å¤šæ§˜æ€§ãŒ{curr_diversity - prev_diversity:+.2f}å¤‰åŒ–"
                    })
        
        return shifts
    
    def _get_cultural_state_snapshot(self, env_id: str) -> Dict[str, Any]:
        """æ–‡åŒ–çŠ¶æ…‹ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ"""
        environment = self.environments[env_id]
        
        return {
            "timestamp": datetime.now(),
            "total_agents": len(environment.agents),
            "cultures_present": list(set(agent.culture.name for agent in environment.agents)),
            "total_interactions": len(environment.events),
            "simulation_turns": environment.current_turn
        }


# ===== ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ =====

# æ–‡åŒ–é€²åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼
culture_simulator = CultureEvolutionSimulator()