"""
ğŸŒˆ æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆæˆã‚·ã‚¹ãƒ†ãƒ 
Higher Kindæ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®åˆæˆãƒ»å¤‰æ›ãƒ»é€²åŒ–ã‚·ã‚¹ãƒ†ãƒ 

Author: ã‚·ã‚¹ãƒ†ãƒ³ã‚¹ã‚«ãƒ•ã‚§ ãƒ†ãƒƒã‚¯ãƒãƒ¼ãƒ 
Date: 2025-06-21
"""

from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import random
import math

from app.models.culture_simulation_base import (
    CultureProtocol, ValueToken, Meme, Practice, Myth,
    ValueCategory, PracticeContext, CultureOrigin
)


class BlendStrategy(Enum):
    WEIGHTED_AVERAGE = "weighted_average"   # é‡ã¿ä»˜ãå¹³å‡
    DOMINANT_MERGE = "dominant_merge"       # æ”¯é…çš„è¦ç´ ä¸­å¿ƒ
    CREATIVE_FUSION = "creative_fusion"     # å‰µé€ çš„èåˆ
    SELECTIVE_COMBINE = "selective_combine"  # é¸æŠçš„çµ„ã¿åˆã‚ã›


class AmplificationTarget(Enum):
    INTUITION = "intuition"
    LOGIC = "logic"
    CREATIVITY = "creativity"
    EFFICIENCY = "efficiency"
    EMPATHY = "empathy"
    HARMONY = "harmony"
    INNOVATION = "innovation"


@dataclass
class BlendingResult:
    """åˆæˆçµæœ"""
    new_protocol: CultureProtocol
    blend_ratio: Dict[str, float]
    strategy_used: BlendStrategy
    synthesis_notes: List[str]
    compatibility_score: float
    novelty_score: float
    timestamp: datetime


class CultureProtocolComposer:
    """æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆæˆå™¨"""
    
    def __init__(self):
        self.blend_history: List[BlendingResult] = []
        self.synthesis_templates = self._initialize_synthesis_templates()
    
    def blend_protocols(
        self,
        protocols: List[CultureProtocol],
        weights: List[float],
        strategy: BlendStrategy = BlendStrategy.CREATIVE_FUSION,
        custom_name: Optional[str] = None
    ) -> BlendingResult:
        """è¤‡æ•°ã®æ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’åˆæˆ"""
        
        if len(protocols) != len(weights):
            raise ValueError("ãƒ—ãƒ­ãƒˆã‚³ãƒ«æ•°ã¨é‡ã¿ã®æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“")
        
        if len(protocols) < 2:
            raise ValueError("å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ãŒå¿…è¦ã§ã™")
        
        # é‡ã¿ã‚’æ­£è¦åŒ–
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # æˆ¦ç•¥ã«åŸºã¥ãåˆæˆ
        if strategy == BlendStrategy.WEIGHTED_AVERAGE:
            result = self._weighted_average_blend(protocols, normalized_weights)
        elif strategy == BlendStrategy.DOMINANT_MERGE:
            result = self._dominant_merge_blend(protocols, normalized_weights)
        elif strategy == BlendStrategy.CREATIVE_FUSION:
            result = self._creative_fusion_blend(protocols, normalized_weights)
        elif strategy == BlendStrategy.SELECTIVE_COMBINE:
            result = self._selective_combine_blend(protocols, normalized_weights)
        else:
            raise ValueError(f"æœªå¯¾å¿œã®åˆæˆæˆ¦ç•¥: {strategy}")
        
        # ã‚«ã‚¹ã‚¿ãƒ åã®è¨­å®š
        if custom_name:
            result['protocol'].name = custom_name
            result['protocol'].id = f"custom-{custom_name.lower().replace(' ', '-')}-v1"
        
        # åˆæˆçµæœã‚’è¨˜éŒ²
        blend_result = BlendingResult(
            new_protocol=result['protocol'],
            blend_ratio={protocols[i].name: normalized_weights[i] for i in range(len(protocols))},
            strategy_used=strategy,
            synthesis_notes=result['notes'],
            compatibility_score=self._calculate_compatibility_score(protocols),
            novelty_score=self._calculate_novelty_score(result['protocol'], protocols),
            timestamp=datetime.now()
        )
        
        self.blend_history.append(blend_result)
        return blend_result
    
    def _weighted_average_blend(self, protocols: List[CultureProtocol], weights: List[float]) -> Dict[str, Any]:
        """é‡ã¿ä»˜ãå¹³å‡ã«ã‚ˆã‚‹åˆæˆ"""
        
        # ä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆæˆ
        value_tokens = self._blend_value_tokens(protocols, weights, "average")
        
        # ãƒŸãƒ¼ãƒ ã®åˆæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        memes = []
        for i, protocol in enumerate(protocols):
            for meme in protocol.memes:
                # é‡ã¿ã«å¿œã˜ã¦é¸æŠ
                if weights[i] >= 0.3:  # 30%ä»¥ä¸Šã®é‡ã¿ã§æ¡ç”¨
                    memes.append(meme)
        
        # æ§˜å¼ã®åˆæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        practices = []
        for i, protocol in enumerate(protocols):
            for practice in protocol.practices:
                if weights[i] >= 0.3:
                    practices.append(practice)
        
        # ç¥è©±ã®åˆæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        myths = []
        for i, protocol in enumerate(protocols):
            for myth in protocol.myths:
                if weights[i] >= 0.3:
                    myths.append(myth)
        
        # æ–°ã—ã„ãƒ—ãƒ­ãƒˆã‚³ãƒ«ä½œæˆ
        blended_name = " Ã— ".join([p.name for p in protocols])
        new_protocol = CultureProtocol(
            id=f"blend-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            name=f"èåˆãƒ—ãƒ­ãƒˆã‚³ãƒ«: {blended_name}",
            description=f"é‡ã¿ä»˜ãå¹³å‡ã«ã‚ˆã‚‹{len(protocols)}æ–‡åŒ–ã®èåˆ",
            value_tokens=value_tokens,
            memes=memes,
            practices=practices,
            myths=myths,
            origin=CultureOrigin.SYNTHETIC,
            version="1.0.0",
            created_at=datetime.now(),
            tags=["fusion", "weighted_average"] + [tag for p in protocols for tag in p.tags]
        )
        
        return {
            'protocol': new_protocol,
            'notes': [
                f"é‡ã¿ä»˜ãå¹³å‡ã«ã‚ˆã‚Š{len(protocols)}æ–‡åŒ–ã‚’èåˆ",
                f"é‡ã¿é…åˆ†: {', '.join(f'{p.name}({w:.2f})' for p, w in zip(protocols, weights))}",
                "å„è¦ç´ ã®æ•°å€¤çš„å¹³å‡ã‚’åŸºã«å®‰å®šã—ãŸåˆæˆã‚’å®Ÿç¾"
            ]
        }
    
    def _creative_fusion_blend(self, protocols: List[CultureProtocol], weights: List[float]) -> Dict[str, Any]:
        """å‰µé€ çš„èåˆã«ã‚ˆã‚‹åˆæˆ"""
        
        # ä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ã®å‰µé€ çš„åˆæˆ
        value_tokens = self._blend_value_tokens(protocols, weights, "creative")
        
        # ãƒŸãƒ¼ãƒ ã®å‰µé€ çš„å¤‰ç•°
        memes = self._creative_meme_fusion(protocols, weights)
        
        # æ§˜å¼ã®é©æ–°çš„çµ„ã¿åˆã‚ã›
        practices = self._creative_practice_fusion(protocols, weights)
        
        # ç¥è©±ã®å‰µé€ çš„çµ±åˆ
        myths = self._creative_myth_fusion(protocols, weights)
        
        # å‰µé€ çš„åˆæˆå
        fusion_concepts = self._generate_fusion_concepts(protocols)
        fusion_name = random.choice(fusion_concepts)
        
        new_protocol = CultureProtocol(
            id=f"creative-fusion-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            name=fusion_name,
            description=f"å‰µé€ çš„èåˆã«ã‚ˆã‚Šç”Ÿã¾ã‚ŒãŸæ–°èªçŸ¥æ§˜å¼: {', '.join(p.name for p in protocols)}ã®é©æ–°çš„çµ±åˆ",
            value_tokens=value_tokens,
            memes=memes,
            practices=practices,
            myths=myths,
            origin=CultureOrigin.EVOLVED,
            version="1.0.0",
            created_at=datetime.now(),
            tags=["creative_fusion", "emergent", "innovative"] + [tag for p in protocols for tag in p.tags[:2]]
        )
        
        return {
            'protocol': new_protocol,
            'notes': [
                f"å‰µé€ çš„èåˆã«ã‚ˆã‚Šæ–°ã—ã„èªçŸ¥æ§˜å¼ '{fusion_name}' ã‚’å‰µé€ ",
                "å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ ã‚’è¶…ãˆãŸé©æ–°çš„ãªè¦ç´ çµ„ã¿åˆã‚ã›",
                "äºˆæœŸã—ãªã„ç›¸ä¹—åŠ¹æœã«ã‚ˆã‚‹æ–°ã—ã„æ–‡åŒ–çš„å¯èƒ½æ€§ã®å‰µç™º",
                f"èåˆæ¦‚å¿µ: {', '.join(fusion_concepts[:3])}"
            ]
        }
    
    def _dominant_merge_blend(self, protocols: List[CultureProtocol], weights: List[float]) -> Dict[str, Any]:
        """æ”¯é…çš„è¦ç´ ä¸­å¿ƒã®åˆæˆ"""
        
        # æœ€ã‚‚é‡ã¿ã®å¤§ãã„ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’åŸºç›¤ã¨ã™ã‚‹
        dominant_idx = weights.index(max(weights))
        dominant_protocol = protocols[dominant_idx]
        
        # åŸºç›¤ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ä»–ã®è¦ç´ ã‚’è¿½åŠ 
        value_tokens = list(dominant_protocol.value_tokens)
        memes = list(dominant_protocol.memes)
        practices = list(dominant_protocol.practices)
        myths = list(dominant_protocol.myths)
        
        # ä»–ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰é¸æŠçš„ã«è¦ç´ ã‚’è¿½åŠ 
        for i, protocol in enumerate(protocols):
            if i == dominant_idx:
                continue
            
            weight = weights[i]
            selection_threshold = 0.3  # 30%ä»¥ä¸Šã®é‡ã¿ã§è¦ç´ é¸æŠ
            
            if weight >= selection_threshold:
                # ä¾¡å€¤è¦³ã®è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰
                for token in protocol.value_tokens[:2]:  # ä¸Šä½2ã¤ã¾ã§
                    if not any(vt.name == token.name for vt in value_tokens):
                        # é‡ã¿ã«å¿œã˜ã¦ä¾¡å€¤ã‚’èª¿æ•´
                        adjusted_token = ValueToken(
                            name=token.name,
                            value=token.value * weight,
                            influence=token.influence * weight,
                            category=token.category
                        )
                        value_tokens.append(adjusted_token)
                
                # ãƒŸãƒ¼ãƒ ã®è¿½åŠ 
                if protocol.memes:
                    selected_meme = protocol.memes[0]  # æœ€åˆã®ãƒŸãƒ¼ãƒ ã‚’æ¡ç”¨
                    memes.append(selected_meme)
        
        new_protocol = CultureProtocol(
            id=f"dominant-merge-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            name=f"{dominant_protocol.name}æ‹¡å¼µãƒ—ãƒ­ãƒˆã‚³ãƒ«",
            description=f"{dominant_protocol.name}ã‚’åŸºç›¤ã¨ã—ãŸå¤šæ–‡åŒ–çµ±åˆãƒ—ãƒ­ãƒˆã‚³ãƒ«",
            value_tokens=value_tokens,
            memes=memes,
            practices=practices,
            myths=myths,
            origin=CultureOrigin.EVOLVED,
            version="1.0.0",
            created_at=datetime.now(),
            tags=["dominant_merge", dominant_protocol.name.lower()] + [tag for p in protocols for tag in p.tags[:1]]
        )
        
        return {
            'protocol': new_protocol,
            'notes': [
                f"{dominant_protocol.name}ã‚’æ”¯é…çš„åŸºç›¤ã¨ã—ã¦æ¡ç”¨",
                f"é‡ã¿{weights[dominant_idx]:.2f}ã§åŸºç›¤ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ§‹é€ ã‚’ç¶­æŒ",
                "ä»–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰é¸æŠçš„ã«è£œå¼·è¦ç´ ã‚’çµ±åˆ",
                "å®‰å®šæ€§ã¨ä¸€è²«æ€§ã‚’é‡è¦–ã—ãŸæ®µéšçš„æ‹¡å¼µ"
            ]
        }
    
    def _selective_combine_blend(self, protocols: List[CultureProtocol], weights: List[float]) -> Dict[str, Any]:
        """é¸æŠçš„çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹åˆæˆ"""
        
        # å„è¦ç´ ã‚’å€‹åˆ¥ã«æœ€é©é¸æŠ
        value_tokens = []
        memes = []
        practices = []
        myths = []
        
        # ä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ã®é¸æŠçš„çµ„ã¿åˆã‚ã›
        all_value_tokens = []
        for i, protocol in enumerate(protocols):
            for token in protocol.value_tokens:
                all_value_tokens.append((token, weights[i]))
        
        # é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’é¸æŠ
        all_value_tokens.sort(key=lambda x: x[0].value * x[1], reverse=True)
        selected_values = set()
        
        for token, weight in all_value_tokens[:5]:  # ä¸Šä½5ã¤ã¾ã§
            if token.name not in selected_values:
                value_tokens.append(token)
                selected_values.add(token.name)
        
        # ãƒŸãƒ¼ãƒ ã®é¸æŠçš„çµ„ã¿åˆã‚ã›
        all_memes = []
        for i, protocol in enumerate(protocols):
            for meme in protocol.memes:
                all_memes.append((meme, weights[i]))
        
        all_memes.sort(key=lambda x: x[0].resonance * x[1], reverse=True)
        for meme, weight in all_memes[:3]:  # ä¸Šä½3ã¤ã¾ã§
            memes.append(meme)
        
        # æ§˜å¼ã®é¸æŠçš„çµ„ã¿åˆã‚ã›
        all_practices = []
        for i, protocol in enumerate(protocols):
            for practice in protocol.practices:
                all_practices.append((practice, weights[i]))
        
        all_practices.sort(key=lambda x: x[0].frequency * x[1], reverse=True)
        for practice, weight in all_practices[:4]:  # ä¸Šä½4ã¤ã¾ã§
            practices.append(practice)
        
        # ç¥è©±ã®é¸æŠçš„çµ„ã¿åˆã‚ã›
        all_myths = []
        for i, protocol in enumerate(protocols):
            for myth in protocol.myths:
                all_myths.append((myth, weights[i]))
        
        all_myths.sort(key=lambda x: x[0].influence * x[1], reverse=True)
        for myth, weight in all_myths[:2]:  # ä¸Šä½2ã¤ã¾ã§
            myths.append(myth)
        
        new_protocol = CultureProtocol(
            id=f"selective-combine-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            name=f"é¸æŠçµ±åˆãƒ—ãƒ­ãƒˆã‚³ãƒ«: {len(protocols)}æ–‡åŒ–ç²¾é¸",
            description="å„æ–‡åŒ–ã‹ã‚‰æœ€é©è¦ç´ ã‚’é¸æŠçš„ã«çµ±åˆã—ãŸåŠ¹ç‡çš„èªçŸ¥æ§˜å¼",
            value_tokens=value_tokens,
            memes=memes,
            practices=practices,
            myths=myths,
            origin=CultureOrigin.SYNTHETIC,
            version="1.0.0",
            created_at=datetime.now(),
            tags=["selective", "optimized", "curated"] + [p.name.lower()[:4] for p in protocols]
        )
        
        return {
            'protocol': new_protocol,
            'notes': [
                "å„æ–‡åŒ–ã‹ã‚‰é‡ã¿ä»˜ãã‚¹ã‚³ã‚¢ã§æœ€é©è¦ç´ ã‚’é¸æŠ",
                f"ä¾¡å€¤è¦³{len(value_tokens)}ã€ãƒŸãƒ¼ãƒ {len(memes)}ã€æ§˜å¼{len(practices)}ã€ç¥è©±{len(myths)}ã‚’çµ±åˆ",
                "åŠ¹ç‡æ€§ã¨å“è³ªã‚’é‡è¦–ã—ãŸç²¾é¸ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                "å†—é•·æ€§ã‚’æ’é™¤ã—ãŸæ´—ç·´ã•ã‚ŒãŸæ–‡åŒ–è¦ç´ æ§‹æˆ"
            ]
        }
    
    def _blend_value_tokens(self, protocols: List[CultureProtocol], weights: List[float], method: str) -> List[ValueToken]:
        """ä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆæˆ"""
        if method == "average":
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«å¹³å‡å€¤ã‚’è¨ˆç®—
            category_values = {}
            category_counts = {}
            
            for i, protocol in enumerate(protocols):
                for token in protocol.value_tokens:
                    cat = token.category
                    if cat not in category_values:
                        category_values[cat] = 0.0
                        category_counts[cat] = 0.0
                    
                    category_values[cat] += token.value * weights[i]
                    category_counts[cat] += weights[i]
            
            # å¹³å‡åŒ–ã•ã‚ŒãŸä¾¡å€¤è¦³ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½œæˆ
            blended_tokens = []
            for cat, total_value in category_values.items():
                avg_value = total_value / category_counts[cat] if category_counts[cat] > 0 else 0.0
                
                blended_tokens.append(ValueToken(
                    name=f"çµ±åˆ{cat.value}",
                    value=min(avg_value, 1.0),
                    influence=0.7,
                    category=cat
                ))
            
            return blended_tokens
        
        elif method == "creative":
            # å‰µé€ çš„åˆæˆ: æ—¢å­˜è¦ç´ ã®çµ„ã¿åˆã‚ã›ã¨æ–°è¦ç´ ã®å‰µé€ 
            creative_tokens = []
            
            # é«˜ä¾¡å€¤è¦ç´ ã®ç‰¹å®š
            high_value_tokens = []
            for i, protocol in enumerate(protocols):
                for token in protocol.value_tokens:
                    if token.value >= 0.8:
                        high_value_tokens.append((token, weights[i]))
            
            # å‰µé€ çš„ä¾¡å€¤è¦³ã®ç”Ÿæˆ
            if len(high_value_tokens) >= 2:
                # 2ã¤ã®é«˜ä¾¡å€¤è¦ç´ ã‹ã‚‰æ–°ã—ã„ä¾¡å€¤è¦³ã‚’å‰µé€ 
                token1, weight1 = high_value_tokens[0]
                token2, weight2 = high_value_tokens[1]
                
                fusion_value = min((token1.value * weight1 + token2.value * weight2) / (weight1 + weight2), 1.0)
                fusion_influence = min((token1.influence * weight1 + token2.influence * weight2) / (weight1 + weight2), 1.0)
                
                creative_tokens.append(ValueToken(
                    name=f"{token1.name}Ã—{token2.name}èåˆ",
                    value=fusion_value,
                    influence=fusion_influence,
                    category=token1.category  # ç¬¬ä¸€è¦ç´ ã®ã‚«ãƒ†ã‚´ãƒªã‚’æ¡ç”¨
                ))
            
            # æ—¢å­˜ã®é«˜ä¾¡å€¤è¦ç´ ã‚‚ä¿æŒ
            for token, weight in high_value_tokens[:3]:
                creative_tokens.append(ValueToken(
                    name=token.name,
                    value=token.value * 0.9,  # å°‘ã—æ¸›è¡°
                    influence=token.influence * weight,
                    category=token.category
                ))
            
            return creative_tokens
        
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ€åˆã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ä¾¡å€¤è¦³ã‚’æ¡ç”¨
            return protocols[0].value_tokens
    
    def _creative_meme_fusion(self, protocols: List[CultureProtocol], weights: List[float]) -> List[Meme]:
        """å‰µé€ çš„ãƒŸãƒ¼ãƒ èåˆ"""
        fusion_memes = []
        
        # å„ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰ä»£è¡¨çš„ãƒŸãƒ¼ãƒ ã‚’é¸æŠ
        representative_memes = []
        for i, protocol in enumerate(protocols):
            if protocol.memes:
                best_meme = max(protocol.memes, key=lambda m: m.resonance)
                representative_memes.append((best_meme, weights[i]))
        
        if len(representative_memes) >= 2:
            # ãƒŸãƒ¼ãƒ èåˆã®å‰µé€ 
            meme1, weight1 = representative_memes[0]
            meme2, weight2 = representative_memes[1]
            
            # å‰µé€ çš„èåˆãƒŸãƒ¼ãƒ 
            fusion_content = self._generate_fusion_meme_content(meme1.content, meme2.content)
            fusion_memes.append(Meme(
                content=fusion_content,
                virality=(meme1.virality * weight1 + meme2.virality * weight2) / (weight1 + weight2),
                resonance=(meme1.resonance * weight1 + meme2.resonance * weight2) / (weight1 + weight2),
                origin=f"{meme1.origin} Ã— {meme2.origin} èåˆ",
                mutations=[]
            ))
        
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒŸãƒ¼ãƒ ã‚‚ä¸€éƒ¨ä¿æŒ
        for meme, weight in representative_memes:
            if weight >= 0.3:  # 30%ä»¥ä¸Šã®é‡ã¿ãªã‚‰ä¿æŒ
                fusion_memes.append(meme)
        
        return fusion_memes
    
    def _generate_fusion_meme_content(self, content1: str, content2: str) -> str:
        """2ã¤ã®ãƒŸãƒ¼ãƒ å†…å®¹ã‹ã‚‰èåˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""
        fusion_templates = [
            f"{content1}ã€ãã—ã¦{content2}",
            f"{content2}ã«ã‚ˆã‚Š{content1}",
            f"{content1}ã‹ã‚‰{content2}ã¸",
            f"{content1}ã¨{content2}ã®èª¿å’Œ",
            f"å¿ƒã§{content1}ã€ä½“ã§{content2}"
        ]
        return random.choice(fusion_templates)
    
    def _creative_practice_fusion(self, protocols: List[CultureProtocol], weights: List[float]) -> List[Practice]:
        """å‰µé€ çš„æ§˜å¼èåˆ"""
        fusion_practices = []
        
        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«é–“ã§æ§˜å¼ã®çµ„ã¿åˆã‚ã›ã‚’è©¦è¡Œ
        all_practices = []
        for i, protocol in enumerate(protocols):
            for practice in protocol.practices:
                all_practices.append((practice, weights[i]))
        
        # é«˜é »åº¦ãƒ»é«˜é‡ã¿æ§˜å¼ã‚’åŸºã«æ–°æ§˜å¼ã‚’å‰µé€ 
        all_practices.sort(key=lambda x: x[0].frequency * x[1], reverse=True)
        
        if len(all_practices) >= 2:
            practice1, weight1 = all_practices[0]
            practice2, weight2 = all_practices[1]
            
            # èåˆæ§˜å¼ã®å‰µé€ 
            fusion_practice = Practice(
                name=f"{practice1.name}+{practice2.name}çµ±åˆæ³•",
                description=f"{practice1.description}ã‚’{practice2.description}ã¨çµ„ã¿åˆã‚ã›ãŸçµ±åˆçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
                frequency=(practice1.frequency * weight1 + practice2.frequency * weight2) / (weight1 + weight2),
                context=practice1.context,  # ã‚ˆã‚Šé‡è¦ãªæ–‡è„ˆã‚’æ¡ç”¨
                triggers=practice1.triggers + practice2.triggers,
                outcomes=practice1.outcomes + practice2.outcomes
            )
            fusion_practices.append(fusion_practice)
        
        # æ—¢å­˜ã®æ§˜å¼ã‚‚é¸æŠçš„ã«ä¿æŒ
        for practice, weight in all_practices[:3]:
            if weight >= 0.25:
                fusion_practices.append(practice)
        
        return fusion_practices
    
    def _creative_myth_fusion(self, protocols: List[CultureProtocol], weights: List[float]) -> List[Myth]:
        """å‰µé€ çš„ç¥è©±èåˆ"""
        fusion_myths = []
        
        # å„ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰å½±éŸ¿åŠ›ã®é«˜ã„ç¥è©±ã‚’é¸æŠ
        high_influence_myths = []
        for i, protocol in enumerate(protocols):
            for myth in protocol.myths:
                if myth.influence >= 0.7:
                    high_influence_myths.append((myth, weights[i]))
        
        if len(high_influence_myths) >= 2:
            myth1, weight1 = high_influence_myths[0]
            myth2, weight2 = high_influence_myths[1]
            
            # èåˆç¥è©±ã®å‰µé€ 
            fusion_myth = Myth(
                name=f"{myth1.name}ã¨{myth2.name}ã®äº¤éŸ¿",
                narrative=f"{myth1.narrative}ã€‚ãã—ã¦{myth2.narrative}ã€‚äºŒã¤ã®ç‰©èªãŒäº¤ã‚ã‚Šã€æ–°ãŸãªä¼èª¬ãŒç”Ÿã¾ã‚Œã‚‹ã€‚",
                symbolism=f"{myth1.symbolism}ã¨{myth2.symbolism}ã®çµ±åˆã«ã‚ˆã‚‹å…¨ä½“æ€§",
                archetypes=list(set(myth1.archetypes + myth2.archetypes)),
                influence=(myth1.influence * weight1 + myth2.influence * weight2) / (weight1 + weight2)
            )
            fusion_myths.append(fusion_myth)
        
        return fusion_myths
    
    def _generate_fusion_concepts(self, protocols: List[CultureProtocol]) -> List[str]:
        """èåˆæ¦‚å¿µåã®ç”Ÿæˆ"""
        concept_words = []
        
        # å„ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        for protocol in protocols:
            # åå‰ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            if "ã‚°ãƒ©ãƒ´ã‚£ã‚¿" in protocol.name:
                concept_words.extend(["é‡åŠ›", "å¼•åŠ›", "æ ¸å¿ƒ"])
            if "ãƒ‡ãƒ«ã‚¿" in protocol.name:
                concept_words.extend(["å¤‰åŒ–", "å·®åˆ†", "è»¢æ›"])
            if "ã‚«ãƒ‰ãƒŸã‚ªãƒ³" in protocol.name:
                concept_words.extend(["å…±é³´", "æŒ¯å‹•", "èª¿å’Œ"])
            
            # ä¾¡å€¤è¦³ã‹ã‚‰æ¦‚å¿µæŠ½å‡º
            for token in protocol.value_tokens:
                if "ç›´æ„Ÿ" in token.name:
                    concept_words.extend(["ç›´æ„Ÿ", "æ„ŸçŸ¥", "å¯ŸçŸ¥"])
                if "å› æœ" in token.name:
                    concept_words.extend(["å› æœ", "é€£é–", "çµæœ"])
        
        # å‰µé€ çš„çµ„ã¿åˆã‚ã›
        fusion_concepts = [
            f"{concept_words[0]}Ã—{concept_words[1]}ãƒ—ãƒ­ãƒˆã‚³ãƒ«" if len(concept_words) >= 2 else "èåˆãƒ—ãƒ­ãƒˆã‚³ãƒ«",
            f"çµ±åˆ{concept_words[0]}ã‚·ã‚¹ãƒ†ãƒ " if concept_words else "çµ±åˆã‚·ã‚¹ãƒ†ãƒ ",
            f"æ–°ä¸–ä»£{concept_words[0]}èªçŸ¥" if concept_words else "æ–°ä¸–ä»£èªçŸ¥",
            f"{concept_words[0]}ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰" if concept_words else "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰",
            f"é€²åŒ–å‹{concept_words[0]}æ§˜å¼" if concept_words else "é€²åŒ–å‹æ§˜å¼"
        ]
        
        return fusion_concepts
    
    def _calculate_compatibility_score(self, protocols: List[CultureProtocol]) -> float:
        """ãƒ—ãƒ­ãƒˆã‚³ãƒ«é–“ã®ç›¸æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if len(protocols) < 2:
            return 1.0
        
        total_compatibility = 0.0
        pair_count = 0
        
        for i in range(len(protocols)):
            for j in range(i + 1, len(protocols)):
                compatibility = self._calculate_pair_compatibility(protocols[i], protocols[j])
                total_compatibility += compatibility
                pair_count += 1
        
        return total_compatibility / pair_count if pair_count > 0 else 0.0
    
    def _calculate_pair_compatibility(self, protocol1: CultureProtocol, protocol2: CultureProtocol) -> float:
        """2ã¤ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«é–“ã®ç›¸æ€§è¨ˆç®—"""
        compatibility_factors = []
        
        # ä¾¡å€¤è¦³ã‚«ãƒ†ã‚´ãƒªã®é‡è¤‡åº¦
        cats1 = set(token.category for token in protocol1.value_tokens)
        cats2 = set(token.category for token in protocol2.value_tokens)
        category_overlap = len(cats1 & cats2) / len(cats1 | cats2) if cats1 | cats2 else 0.0
        compatibility_factors.append(category_overlap)
        
        # æ§˜å¼æ–‡è„ˆã®é‡è¤‡åº¦
        contexts1 = set(practice.context for practice in protocol1.practices)
        contexts2 = set(practice.context for practice in protocol2.practices)
        context_overlap = len(contexts1 & contexts2) / len(contexts1 | contexts2) if contexts1 | contexts2 else 0.0
        compatibility_factors.append(context_overlap)
        
        # ã‚¿ã‚°ã®é‡è¤‡åº¦
        tags1 = set(protocol1.tags)
        tags2 = set(protocol2.tags)
        tag_overlap = len(tags1 & tags2) / len(tags1 | tags2) if tags1 | tags2 else 0.0
        compatibility_factors.append(tag_overlap)
        
        return sum(compatibility_factors) / len(compatibility_factors)
    
    def _calculate_novelty_score(self, new_protocol: CultureProtocol, source_protocols: List[CultureProtocol]) -> float:
        """æ–°è¦æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        novelty_factors = []
        
        # æ–°ã—ã„ä¾¡å€¤è¦³ã®å‰²åˆ
        new_value_names = set(token.name for token in new_protocol.value_tokens)
        source_value_names = set()
        for protocol in source_protocols:
            source_value_names.update(token.name for token in protocol.value_tokens)
        
        new_values_ratio = len(new_value_names - source_value_names) / len(new_value_names) if new_value_names else 0.0
        novelty_factors.append(new_values_ratio)
        
        # æ–°ã—ã„ãƒŸãƒ¼ãƒ ã®å‰²åˆ
        new_meme_contents = set(meme.content for meme in new_protocol.memes)
        source_meme_contents = set()
        for protocol in source_protocols:
            source_meme_contents.update(meme.content for meme in protocol.memes)
        
        new_memes_ratio = len(new_meme_contents - source_meme_contents) / len(new_meme_contents) if new_meme_contents else 0.0
        novelty_factors.append(new_memes_ratio)
        
        # è¦ç´ çµ„ã¿åˆã‚ã›ã®è¤‡é›‘ã•
        element_count = len(new_protocol.value_tokens) + len(new_protocol.memes) + len(new_protocol.practices) + len(new_protocol.myths)
        complexity_score = min(element_count / 10.0, 1.0)  # 10è¦ç´ ã§æœ€å¤§
        novelty_factors.append(complexity_score)
        
        return sum(novelty_factors) / len(novelty_factors)
    
    def amplify_aspect(
        self,
        protocol: CultureProtocol,
        target: AmplificationTarget,
        intensity: float = 1.5
    ) -> CultureProtocol:
        """ç‰¹å®šã®å´é¢ã‚’å¢—å¹…"""
        
        # å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
        amplified_protocol = CultureProtocol(
            id=f"{protocol.id}-amplified-{target.value}",
            name=f"{protocol.name}ï¼ˆ{target.value}å¢—å¹…ï¼‰",
            description=f"{protocol.description} - {target.value}ã‚’{intensity}å€ã«å¢—å¹…",
            value_tokens=list(protocol.value_tokens),
            memes=list(protocol.memes),
            practices=list(protocol.practices),
            myths=list(protocol.myths),
            origin=CultureOrigin.EVOLVED,
            version=f"{protocol.version}+{target.value}",
            created_at=datetime.now(),
            tags=protocol.tags + [f"amplified_{target.value}"]
        )
        
        # å¯¾è±¡ã«å¿œã˜ãŸå¢—å¹…
        if target == AmplificationTarget.INTUITION:
            self._amplify_intuition(amplified_protocol, intensity)
        elif target == AmplificationTarget.LOGIC:
            self._amplify_logic(amplified_protocol, intensity)
        elif target == AmplificationTarget.CREATIVITY:
            self._amplify_creativity(amplified_protocol, intensity)
        # ä»–ã®å¢—å¹…ã‚¿ã‚¤ãƒ—ã‚‚åŒæ§˜ã«å®Ÿè£…å¯èƒ½
        
        return amplified_protocol
    
    def _amplify_intuition(self, protocol: CultureProtocol, intensity: float):
        """ç›´æ„Ÿã®å¢—å¹…"""
        for token in protocol.value_tokens:
            if "ç›´æ„Ÿ" in token.name or "æ„ŸçŸ¥" in token.name:
                token.value = min(token.value * intensity, 1.0)
                token.influence = min(token.influence * intensity, 1.0)
    
    def _amplify_logic(self, protocol: CultureProtocol, intensity: float):
        """è«–ç†ã®å¢—å¹…"""
        for token in protocol.value_tokens:
            if "è«–ç†" in token.name or "åˆ†æ" in token.name:
                token.value = min(token.value * intensity, 1.0)
                token.influence = min(token.influence * intensity, 1.0)
    
    def _amplify_creativity(self, protocol: CultureProtocol, intensity: float):
        """å‰µé€ æ€§ã®å¢—å¹…"""
        for token in protocol.value_tokens:
            if "å‰µé€ " in token.name or "ç™ºæƒ³" in token.name:
                token.value = min(token.value * intensity, 1.0)
                token.influence = min(token.influence * intensity, 1.0)
    
    def _initialize_synthesis_templates(self) -> Dict[str, Any]:
        """åˆæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®åˆæœŸåŒ–"""
        return {
            "naming_patterns": [
                "{name1}Ã—{name2}ãƒ—ãƒ­ãƒˆã‚³ãƒ«",
                "çµ±åˆ{concept}ã‚·ã‚¹ãƒ†ãƒ ",
                "æ–°ä¸–ä»£{attribute}èªçŸ¥",
                "{element}ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰",
                "é€²åŒ–å‹{characteristic}æ§˜å¼"
            ],
            "description_templates": [
                "{source1}ã¨{source2}ã®é©æ–°çš„èåˆã«ã‚ˆã‚‹æ–°èªçŸ¥æ§˜å¼",
                "{concept}ã«ç‰¹åŒ–ã—ãŸçµ±åˆæ–‡åŒ–ãƒ—ãƒ­ãƒˆã‚³ãƒ«",
                "è¤‡æ•°æ–‡åŒ–ã®æœ€é©è¦ç´ ã‚’çµ±åˆã—ãŸåŠ¹ç‡çš„æ€è€ƒã‚·ã‚¹ãƒ†ãƒ "
            ]
        }
    
    def get_blend_recommendations(self, protocols: List[CultureProtocol]) -> List[Dict[str, Any]]:
        """æ¨å¥¨åˆæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ææ¡ˆ"""
        recommendations = []
        
        # ç›¸æ€§ã®è‰¯ã„çµ„ã¿åˆã‚ã›ã‚’ç‰¹å®š
        for i in range(len(protocols)):
            for j in range(i + 1, len(protocols)):
                compatibility = self._calculate_pair_compatibility(protocols[i], protocols[j])
                
                if compatibility >= 0.3:  # 30%ä»¥ä¸Šã®ç›¸æ€§
                    recommendations.append({
                        "protocols": [protocols[i].name, protocols[j].name],
                        "compatibility_score": compatibility,
                        "recommended_strategy": BlendStrategy.CREATIVE_FUSION if compatibility >= 0.6 else BlendStrategy.SELECTIVE_COMBINE,
                        "suggested_weights": [0.6, 0.4] if compatibility >= 0.6 else [0.5, 0.5],
                        "expected_benefits": self._predict_blend_benefits(protocols[i], protocols[j], compatibility)
                    })
        
        # ç›¸æ€§é †ã«ã‚½ãƒ¼ãƒˆ
        recommendations.sort(key=lambda x: x["compatibility_score"], reverse=True)
        return recommendations[:5]  # ä¸Šä½5ã¤ã¾ã§
    
    def _predict_blend_benefits(self, protocol1: CultureProtocol, protocol2: CultureProtocol, compatibility: float) -> List[str]:
        """åˆæˆã«ã‚ˆã‚‹æœŸå¾…åŠ¹æœã®äºˆæ¸¬"""
        benefits = []
        
        if compatibility >= 0.7:
            benefits.append("é«˜ã„ç›¸æ€§ã«ã‚ˆã‚‹å®‰å®šã—ãŸèåˆåŠ¹æœ")
        
        # ä¾¡å€¤è¦³ã®è£œå®Œæ€§ãƒã‚§ãƒƒã‚¯
        cats1 = set(token.category for token in protocol1.value_tokens)
        cats2 = set(token.category for token in protocol2.value_tokens)
        
        if ValueCategory.COGNITIVE in cats1 and ValueCategory.EMOTIONAL in cats2:
            benefits.append("èªçŸ¥ã¨æ„Ÿæƒ…ã®ãƒãƒ©ãƒ³ã‚¹å–ã‚ŒãŸçµ±åˆ")
        
        if ValueCategory.TEMPORAL in cats1 and ValueCategory.SOCIAL in cats2:
            benefits.append("æ™‚é–“èªè­˜ã¨ç¤¾ä¼šæ€§ã®ç›¸ä¹—åŠ¹æœ")
        
        # æ§˜å¼ã®å¤šæ§˜æ€§
        contexts1 = set(practice.context for practice in protocol1.practices)
        contexts2 = set(practice.context for practice in protocol2.practices)
        
        if len(contexts1 | contexts2) >= 3:
            benefits.append("å¤šæ§˜ãªæ–‡è„ˆã§ã®é©ç”¨å¯èƒ½æ€§")
        
        return benefits if benefits else ["åŸºæœ¬çš„ãªæ–‡åŒ–è¦ç´ ã®çµ±åˆåŠ¹æœ"]


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
culture_composer = CultureProtocolComposer()